---
layout: page
---

<article>

<h1 id="Tutorials">Tutorials</h1>

<p>The labs for the Gaussian Process Summer School can be downloaded here. All of the lab sheets are written in Python 3 given in Jupyter notebook format.</p>
<p>Details of how to set up your Python environment and on the installation of the necessary libraries are available on the <a href="./gpss18/getting_started">Getting Started</a> page. Ensure you have completed the setup before starting the labs.</p>
<p>Each lab sheet will be made available on the day of the lab, and answers for each will be made shortly after. There are also some extra work sheets, for you to explore in your own time, which give details of other uses of Gaussian processes not covered in the summer school.</p>

<h2 id="Lab-1-:-Gaussian-Processes-Regression">Lab 1 : Gaussian Processes Regression</h2>

<p>This lab is designed to introduce Gaussian processes in a practical way, illustrating the concepts introduced in the first two lectures. The key aspects of Gaussian process regression are covered: the covariance function (aka kernels); sampling a Gaussian process; and the regression model. The notebook will introduce the open source Python library GPy which handles the kernels, regression and optimisation of hyperparameter, allowing us to easily access the results we want.</p>

<table>
<thead><tr>
<th>Lab</th>
<th>Answers</th>
</tr>
</thead>
<tbody>
<tr>
<td><a style="visibility:hidden;" href="./labs/GPSS_Lab1_2018.ipynb">Notebook</a></td>
<td><a style="visibility:hidden;" href="./labs/GPSS_Lab1_2018_Answers.ipynb">Answers</a></td>
</tr>
</tbody>
</table>


<h3 id="Lab-1-Extra-:-Uncertainty-Propagation">Lab 1 Extra : Uncertainty Propagation</h3>

<p><em>description tbc</em></p>
<p><a style="visibility:hidden;" href="./labs/GPSS_Lab1_Extra_2018.ipynb">Notebook</a></p>
  
<h2 id="Lab-2-:-GPs-for-Non-Gaussian-Likelihoods-and-Big-Data">Lab 2 : GPs for Non-Gaussian Likelihoods and Big Data</h2>
  
<p>This lab introduces Gaussian process regression for data with non-Gaussian likelihoods, and shows how this can be applied to classification. The concept of sparse methods for Gaussian process regression is introduced for creating a scalable regression model, and this is combined with a large classification problem.</p>
<p>As with Lab 1, the notebook uses GPy for handling the regression model and likelihoods.</p>
<table>
<thead><tr>
<th>Lab</th>
<th>Answers</th>
</tr>
</thead>
<tbody>
<tr>
<td><a style="visibility:hidden;" href="./labs/GPSS_Lab2_2018.ipynb">Notebook</a></td>
<td><a style="visibility:hidden;" href="./labs/GPSS_Lab2_2018_Answers.ipynb">Answers</a></td>
</tr>
</tbody>
</table>

<h3 id="Lab-2-Extra-:-Multi-Output-GPs">Lab 2 Extra : Multi-Output GPs</h3>

<p><em>description tbc</em></p>
<p><a style="visibility:hidden;" href="./labs/GPSS_Lab2_Extra_2018.ipynb">Notebook</a></p>

<h2 id="Lab-3-:-Bayesian-Optimisation">Lab 3 : Bayesian Optimisation</h2>

<p>This lab introduces the basic concepts of Bayesian optimization with GPyOot. The student will have to build and compare different models and aquisition functions to solve several optimzation problems.</p>
<table>
<thead><tr>
<th>Lab</th>
<th>Answers</th>
</tr>
</thead>
<tbody>
<tr>
<td><a style="visibility:hidden;" href="./labs/GPSS_Lab3_2018.ipynb">Notebook</a></td>
<td><a style="visibility:hidden;" href="./labs/GPSS_Lab3_2018_Answers.ipynb">Answers</a></td>
</tr>
</tbody>
</table>
<h3 id="Lab-3-Extra-:-Gaussian-Process-Latent-Variable-Model">Lab 3 Extra : Gaussian Process Latent Variable Model</h3>

<p><em>description</em></p>
<p><a style="visibility:hidden;" href="./labs/GPSS_Lab3_Extra_2018.ipynb">Notebook</a></p>

</article>
